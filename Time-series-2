Q1. What is meant by time-dependent seasonal components?
- Time-dependent seasonal components refer to recurring patterns or variations in a time series that are influenced by
specific time periods, such as days, months, or years. These components exhibit regular, predictable fluctuations over time and 
contribute to the overall seasonality of the data.

_____________________________________________________________

Q2. How can time-dependent seasonal components be identified in time series data?
- Time-dependent seasonal components can be identified through visual inspection of the data, where recurring patterns become apparent. 
Additionally, statistical methods like decomposition techniques (e.g., seasonal decomposition of time series or STL decomposition) help 
isolate and analyze these components.

python
# Example: Seasonal decomposition of time series in Python using statsmodels
from statsmodels.tsa.seasonal import seasonal_decompose
result = seasonal_decompose(data, model='additive', period=seasonal_period)


_____________________________________________________________

Q3. What are the factors that can influence time-dependent seasonal components?
- Factors influencing time-dependent seasonal components include external events (e.g., holidays), cultural or societal patterns,
and business-related occurrences. These components can also be influenced by changes in consumer behavior or market dynamics during specific time periods.

_____________________________________________________________

Q4. How are autoregression models used in time series analysis and forecasting?
- Autoregression models, such as ARIMA (AutoRegressive Integrated Moving Average), capture the relationship between an observation
and its lagged values. The AR component models the dependency on past observations, allowing the model to capture temporal patterns and trends in the data.

python
# Example: ARIMA modeling in Python using statsmodels
from statsmodels.tsa.arima.model import ARIMA
model = ARIMA(data, order=(p, d, 0))  # AR order (p), differencing (d), MA order (0)
result = model.fit()


_____________________________________________________________

Q5. How do you use autoregression models to make predictions for future time points?
- Autoregression models make predictions by extrapolating the relationship between past observations and future values.
Once the model is trained, it can be used to forecast future time points based on the learned autoregressive patterns.

python
# Example: Making predictions with ARIMA model
future_predictions = result.get_forecast(steps=num_steps).predicted_mean


_____________________________________________________________

Q6. What is a moving average (MA) model and how does it differ from other time series models?
- A moving average (MA) model focuses on modeling the relationship between the current observation and a residual
term representing past forecast errors. It captures short-term fluctuations and noise in the data. MA models, combined 
with autoregressive models, form the basis of ARMA models.

_____________________________________________________________

Q7. What is a mixed ARMA model and how does it differ from an AR or MA model?
- A mixed ARMA model, also known as ARIMA, combines autoregressive (AR) and moving average (MA) components along with differencing.
ARIMA models handle non-stationary data by differencing, capture autoregressive patterns, and model short-term fluctuations with the MA component.
It offers flexibility to handle a broader range of time series patterns.
