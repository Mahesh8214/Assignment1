Q1. What are Eigenvalues and Eigenvectors? How are they related to the Eigen-Decomposition approach? Explain with an example.
- Answer:
  - Eigenvalues (λ) and eigenvectors (v) are concepts in linear algebra associated with square matrices. For a matrix A, the equation (Av = λv) holds, 
    where λ is the eigenvalue and v is the eigenvector.
  - Eigen-Decomposition is a technique that decomposes a matrix into a set of eigenvectors and eigenvalues. For a matrix A, it can be expressed as (A = Q \λ 
    Q^{-1}\), where Q is the matrix of eigenvectors, and Λ is a diagonal matrix with eigenvalues on the diagonal.
  - Example: Let \(A =egin{bmatrix} 4 & 1 \ 2 & 3 \end{bmatrix}\). The eigenvalues can be found by solving the characteristic equation \(|A - \lambda I| = 0\), 
    leading to eigenvalues λ₁ = 5 and λ₂ = 2. The corresponding eigenvectors are found by solving \(Av = \lambda v\), resulting in \(v₁ =egin{bmatrix} 1 \ 1 
    \end{bmatrix}\) for λ₁ and \(v₂ =egin{bmatrix} 1 \ -2 \end{bmatrix}\) for λ₂.

_____________________________________________________________

Q2. What is eigen decomposition and what is its significance in linear algebra?
- Answer:
  - Eigen decomposition is the process of decomposing a square matrix into a set of eigenvectors and eigenvalues. Mathematically, for a matrix A, it can be 
    represented as \(A = Q \λ Q^{-1}\), where Q is the matrix of eigenvectors and Λ is a diagonal matrix with eigenvalues.
  - Significance: Eigen decomposition is fundamental in linear algebra as it provides a way to analyze and understand the behavior of linear transformations. It 
                  simplifies matrix operations, and the diagonalized form makes it easier to perform calculations and derive insights about the matrix.

_____________________________________________________________

Q3. What are the conditions that must be satisfied for a square matrix to be diagonalizable using the Eigen-Decomposition approach? Provide a brief proof to support your answer.
- Answer:
  - A square matrix A is diagonalizable if and only if it has n linearly independent eigenvectors, where n is the size of the matrix.
  - Proof: A matrix A is diagonalizable if there exists an invertible matrix Q such that \(A = Q \Lambda Q^{-1}\). Q is formed by stacking the eigenvectors of A. 
           For A to be diagonalizable, the columns of Q must be linearly independent, ensuring the invertibility of Q. This condition is satisfied when A has n 
           linearly independent eigenvectors.

_____________________________________________________________

Q4. What is the significance of the spectral theorem in the context of the Eigen-Decomposition approach? How is it related to the diagonalizability of a matrix? Explain with an example.
- Answer:
  - The spectral theorem states that for any symmetric matrix A, there exists an orthogonal matrix Q such that \(A = Q \Lambda Q^T\), where Λ is a diagonal matrix 
    containing the eigenvalues of A.
  - This theorem is significant because it guarantees the diagonalizability of symmetric matrices. The diagonalization simplifies computations and reveals 
    essential properties of the matrix.
  - Example: Let \(A =egin{bmatrix} 4 & 1 \ 1 & 3 \end{bmatrix}\), a symmetric matrix. The spectral theorem ensures there exists an orthogonal matrix Q such that \ 
    (A = Q \Lambda Q^T\).

_____________________________________________________________

Q5. How do you find the eigenvalues of a matrix and what do they represent?
- Answer:
  - Eigenvalues are found by solving the characteristic equation \(|A - \lambda I| = 0\), where A is the matrix, λ is the eigenvalue, and I is the identity matrix.
  - Eigenvalues represent the scaling factor by which eigenvectors are stretched or compressed during a linear transformation. They are fundamental in 
    understanding the behavior of linear systems and transformations.

_____________________________________________________________

Q6. What are eigenvectors and how are they related to eigenvalues?
- Answer:
  - Eigenvectors are non-zero vectors that remain in the same direction (up to scaling) after a linear transformation represented by a matrix.
  - They are related to eigenvalues through the equation \(Av = \lambda v\), where A is the matrix, v is the eigenvector, and λ is the eigenvalue. The eigenvector 
     v points in the direction of the transformation, and λ represents the scaling factor.

_____________________________________________________________

Q7. Can you explain the geometric interpretation of eigenvectors and eigenvalues?
- Answer:
  - Eigenvectors represent directions in space that remain unchanged (up to scaling) after a linear transformation.
  - Eigenvalues represent the scaling factors by which the corresponding eigenvectors are stretched or compressed during the transformation.
  - Geometrically, eigenvectors point along the axes of transformation, and eigenvalues determine the scale of the transformation along those axes.

_____________________________________________________________

Q8. What are some real-world applications of eigen decomposition?
- Answer:
  - Image compression: Using eigendecomposition for principal component analysis (PCA) to reduce dimensionality.
  - Quantum mechanics: Diagonalizing matrices in quantum 
